{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting The Blue Alliance Data Through Web API V3\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This jupyer notebook contains all of the data collection and processing for this project. [The Blue Alliance Web API V3](https://www.thebluealliance.com/apidocs/v3) is where the data is collected from. Then the data is processed, with some processes taking longer than others. Running these functions for the first time will take a **long time** (probably around 8 hours). To avoid having to collect the data and run the necessary processing on it, the raw data from the blue alliance, as well as the processed data, is cached in the \"cache/\" directory. The components of those directories are in the .gitignore file, because of its size.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get All Events\n",
    "get_all_events is a function that gets all of the event tags for a given week or weeks. These tags are used to retrieve specific data from The Blue Alliance though it's web API. Currently get_all_events includes both regional and district competitions. There is a total of six weeks of competitions, so week must be less than or equal to 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_events(week=6, only=False):\n",
    "    \"\"\"get_all_events is a function that gets all of the event tags for a given week or weeks.\n",
    "    These tags are used to retrieve specific data from The Blue Alliance though it's web API.\n",
    "    Currently get_all_events includes both regional and district competitions. There is a\n",
    "    total of six weeks of competitions, so week must be less than or equal to 6.\n",
    "    \n",
    "    Examples:\n",
    "        get_all_events(6, False) will get all event tags for weeks 1 thru 6 (inclusive)\n",
    "        get_all_events(6, True) will only get event tags for week 6\n",
    "        \n",
    "    Event type numbers for reference:\n",
    "        0 == regional competitions\n",
    "        1 == district competitions\n",
    "    \"\"\"\n",
    "    \n",
    "    import urllib3\n",
    "    from pandas import read_json\n",
    "    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "    http = urllib3.PoolManager()\n",
    "    auth_key = open('auth.key', 'r').read()\n",
    "    \n",
    "    assert week <= 6, 'Week is not <= 6'\n",
    "    \n",
    "    r = http.request('GET', 'https://www.thebluealliance.com/api/v3/events/2016',\n",
    "                    headers={'X-TBA-Auth-Key': auth_key})\n",
    "    all_events = read_json(r.data.decode('utf-8'))\n",
    "    #print(all_events['week'])\n",
    "    events = []\n",
    "    for i, j in enumerate(all_events['event_type'].values):\n",
    "        if j == 0 or j == 1:\n",
    "            if only:\n",
    "                if all_events['week'][i] == week:\n",
    "                    events.append(all_events['key'][i])\n",
    "            else:\n",
    "                if all_events['week'][i] <= week:\n",
    "                    events.append(all_events['key'][i])\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_all_events(2, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Rankings\n",
    "get_rankings is a function that gets the team ranking information for a given event. The event must be in the format 2016abcd, where 2016 is the year and abcd is the event key. The columns with \"_a\" appending the statistic is the average of that statistic of how many matches the team played. The ranking data is cached in the directory 'cache/rankings/' after the first run, but can be reloaded with new=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rankings(event, new=False):\n",
    "    \"\"\"get_rankings is a function that gets the team ranking information for a\n",
    "    given event. The event must be in the format 2016abcd, where 2016 is the year\n",
    "    and abcd is the event key. The columns with \"_a\" appending the statistic is\n",
    "    the average of that statistic of how many matches the team played. The ranking\n",
    "    data is cached in the directory 'cache/rankings/' after the first run, but can\n",
    "    be reloaded with new=True. The output shape is (number of teams, 12). \n",
    "    \n",
    "    Examples:\n",
    "        get_rankings('2016mokc') returns the ranking data for event mokc in year\n",
    "            2016 and caches it if is not already\n",
    "        get_rankings('2016abca', True) forces get_ranking to update the cache for\n",
    "            2016abca and returns the ranking data\n",
    "    \"\"\"\n",
    "    #print(loads(r.data.decode('utf-8'))['sort_order_info'])\n",
    "    import urllib3\n",
    "    from pandas import DataFrame\n",
    "    from json import loads, dump, load\n",
    "    from os.path import isfile\n",
    "    from numpy import array as nparray\n",
    "    \n",
    "    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "    http = urllib3.PoolManager()\n",
    "    auth_key = open('auth.key', 'r').read()\n",
    "    \n",
    "    if isfile('cache/rankings/'+ event +'.json') and not new:\n",
    "        with open('cache/rankings/'+ event +'.json', 'r') as file:\n",
    "            ranks = load(file)\n",
    "    else:\n",
    "        r = http.request('GET', 'https://www.thebluealliance.com/api/v3/event/'+ event +'/rankings',\n",
    "                         headers={'X-TBA-Auth-Key': auth_key})\n",
    "        ranks = loads(r.data.decode('utf-8'))['rankings']\n",
    "        with open('cache/rankings/'+ event +'.json', 'w') as file:\n",
    "            dump(loads(r.data.decode('utf-8'))['rankings'], file)\n",
    "            \n",
    "    ranks = DataFrame.from_dict(ranks).set_index('team_key').drop(['dq', 'qual_average', 'record'], axis=1)\n",
    "    stats = nparray(list(ranks['sort_orders'].values))\n",
    "    ranks['Ranking_Score'] = stats[:,0]\n",
    "    ranks['Ranking_Score_a'] = stats[:,0]/ranks['matches_played']\n",
    "    ranks['Auto'] = stats[:,1]\n",
    "    ranks['Auto_a'] = stats[:,1]/ranks['matches_played']\n",
    "    ranks['Scale/Challenge'] = stats[:,2]\n",
    "    ranks['Scale/Challenge_a'] = stats[:,2]/ranks['matches_played']\n",
    "    ranks['Goals'] = stats[:,3]\n",
    "    ranks['Goals_a'] = stats[:,3]/ranks['matches_played']\n",
    "    ranks['Defense'] = stats[:,4]\n",
    "    ranks['Defense_a'] = stats[:,4]/ranks['matches_played']\n",
    "    ranks['Ranking_Score_a'] = nparray(list(ranks['extra_stats'].values)).reshape(-1,)\n",
    "    ranks.drop(['sort_orders','extra_stats'], axis=1, inplace=True)\n",
    "    return ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_rankings('2016abca')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Matches\n",
    "get_matches is a function that the match by match data for a given event tag. get_matches follows the same event tag and cache policies as get_rankings, with the cache being in 'cache/matches/'. get_matches also one-hot encodes data columns with multiple non-numerical inputs. This was done by hand to ensure proper one-hot encoding without redudancy. The output shape is (number of matches, 173)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matches(event, new=False):\n",
    "    \"\"\"get_matches is a function that the match by match data for a given event tag.\n",
    "    get_matches follows the same event tag and cache policies as get_rankings.\n",
    "    get_matches also one-hot encodes data columns with multiple non-numerical inputs.\n",
    "    This was done by hand to ensure proper one-hot encoding without redudancy. The\n",
    "    output shape is (number of matches, 173).\n",
    "    \n",
    "    Examples:\n",
    "        get_matches('2016mokc') returns the match data and caches the data if not\n",
    "            already done\n",
    "        get_matches('2016abca', True) forces get_matches to update the cache and\n",
    "            returns the match data\n",
    "    \"\"\"\n",
    "    \n",
    "    import urllib3\n",
    "    from pandas import read_json\n",
    "    from os.path import isfile\n",
    "    from json import dump, loads\n",
    "    from numpy import array as nparray\n",
    "    from numpy import where\n",
    "    \n",
    "    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "    http = urllib3.PoolManager()\n",
    "    auth_key = open('auth.key', 'r').read()\n",
    "    \n",
    "    if isfile('cache/matches/'+ event +'.json') and not new:\n",
    "        with open('cache/matches/'+ event +'.json', 'r') as file:\n",
    "            matches = read_json(file)\n",
    "    else:\n",
    "        r = http.request('GET', 'https://www.thebluealliance.com/api/v3/event/'+ event +'/matches',\n",
    "                         headers={'X-TBA-Auth-Key': auth_key})\n",
    "        matches = read_json(r.data.decode('utf-8'))\n",
    "        with open('cache/matches/'+ event +'.json', 'w') as file:\n",
    "            dump(loads(r.data.decode('utf-8')), file)\n",
    "    \n",
    "    matches = matches.set_index(['comp_level', 'match_number']).drop(['actual_time', 'post_result_time',\n",
    "                                                                                'predicted_time', 'videos',\n",
    "                                                                                'time', 'set_number',\n",
    "                                                                                'event_key', 'key'], axis=1)\n",
    "    alliances = matches['alliances']\n",
    "    blue_teams = []\n",
    "    blue_score = []\n",
    "    red_teams = []\n",
    "    red_score = []\n",
    "    for thing in alliances:\n",
    "        blue_teams.append(thing['blue']['team_keys'])\n",
    "        blue_score.append(thing['blue']['score'])\n",
    "        red_teams.append(thing['red']['team_keys'])\n",
    "        red_score.append(thing['red']['score'])\n",
    "    blue_teams = nparray(blue_teams)\n",
    "    red_teams = nparray(red_teams)\n",
    "    matches['blue_team1'] = blue_teams[:,0]\n",
    "    matches['blue_team2'] = blue_teams[:,1]\n",
    "    matches['blue_team3'] = blue_teams[:,2]\n",
    "    matches['blue_score'] = blue_score\n",
    "    matches['red_team1'] = red_teams[:,0]\n",
    "    matches['red_team2'] = red_teams[:,1]\n",
    "    matches['red_team3'] = red_teams[:,2]\n",
    "    matches['red_score'] = red_score\n",
    "    matches.drop(['alliances'], axis=1, inplace=True)\n",
    "\n",
    "    keys = list(matches['score_breakdown']['qm'][1]['blue'].keys())\n",
    "    blue_stats = {}\n",
    "    red_stats = {}\n",
    "    for key in keys:\n",
    "        blue_stats[key] = []\n",
    "        red_stats[key] = []\n",
    "\n",
    "    for thing in matches['score_breakdown']:\n",
    "        try:\n",
    "            thing.keys()\n",
    "            for key in keys:\n",
    "                blue_stats[key].append(thing['blue'][key])\n",
    "                red_stats[key].append(thing['red'][key])\n",
    "        except AttributeError:\n",
    "            for key in keys:\n",
    "                blue_stats[key].append(-0)\n",
    "                red_stats[key].append(-0)\n",
    "\n",
    "    for key in keys:\n",
    "        matches['blue_'+key] = blue_stats[key]\n",
    "        matches['red_'+key] = red_stats[key]\n",
    "\n",
    "    for key in ['blue_teleopDefensesBreached', 'red_teleopDefensesBreached',\n",
    "                'blue_teleopTowerCaptured', 'red_teleopTowerCaptured']:\n",
    "        tmp = [1 if x else 0 for x in matches[key]]\n",
    "        matches[key] = tmp\n",
    "\n",
    "    matches.drop('score_breakdown', axis=1, inplace=True)\n",
    "    matches = matches.fillna(0)\n",
    "    \n",
    "    #one hot for defense positions\n",
    "    positions = []\n",
    "    for i in range(2,6):\n",
    "        for j in ['blue_', 'red_']:\n",
    "            for k in ['A_ChevalDeFrise', 'B_Ramparts', 'C_Drawbridge', 'B_Moat', 'A_Portcullis',\n",
    "                      'D_RoughTerrain', 'C_SallyPort', 'D_RockWall']:\n",
    "                positions.append(j+'position'+str(i)+'_'+k)\n",
    "\n",
    "    for item in positions:\n",
    "        if item[0] == 'b':\n",
    "            matches[item] = where(matches[item[:14]].values==item[15:], 1, 0)\n",
    "        else:\n",
    "            matches[item] = where(matches[item[:13]].values==item[14:], 1, 0)\n",
    "\n",
    "    for i in range(2,6):\n",
    "        for j in ['blue_', 'red_']:\n",
    "            matches.drop(j+'position'+str(i), axis=1, inplace=True)\n",
    "           \n",
    "    #one hot for robot auto position \n",
    "    robots = []\n",
    "    for i in range(1,4):\n",
    "        for j in ['blue_', 'red_']:\n",
    "            for k in ['None', 'Reached', 'Crossed']:\n",
    "                robots.append(j+'robot'+str(i)+'Auto_'+k)\n",
    "\n",
    "    for item in robots:\n",
    "        if item[0] == 'b':\n",
    "            matches[item] = where(matches[item[:15]].values==item[16:], 1, 0)\n",
    "        else:\n",
    "            matches[item] = where(matches[item[:14]].values==item[15:], 1, 0)\n",
    "\n",
    "    for i in range(1,4):\n",
    "        for j in ['blue_', 'red_']:\n",
    "            matches.drop(j+'robot'+str(i)+'Auto', axis=1, inplace=True)\n",
    "            \n",
    "    #one-hot for end-game tower action things, yeah\n",
    "    towers = []\n",
    "    for i in ['A', 'B', 'C']:\n",
    "        for j in ['blue_', 'red_']:\n",
    "            for k in ['None', 'Challenged', 'Scaled', 'Both', 'Unknown']:\n",
    "                towers.append(j+'towerFace'+i+'_'+k)\n",
    "    matches['blue_towerFaceA']\n",
    "    for item in towers:\n",
    "        if item[0] == 'b':\n",
    "            matches[item] = where(matches[item[:15]].values==item[16:], 1, 0)\n",
    "        else:\n",
    "            matches[item] = where(matches[item[:14]].values==item[15:], 1, 0)\n",
    "\n",
    "    for i in ['A', 'B', 'C']:\n",
    "        for j in ['blue_', 'red_']:\n",
    "            matches.drop(j+'towerFace'+i, axis=1, inplace=True)\n",
    "\n",
    "    for i in ['A', 'B', 'C']:\n",
    "        for j in ['blue_', 'red_']:\n",
    "            for k in ['Unknown']:\n",
    "                for l in range(len(matches)):\n",
    "                    test0 = matches[j+'towerFace'+i+'_'+k][l]\n",
    "                    if test0:\n",
    "                        test1 = matches[j+'teleopChallengePoints'][l]-(matches[j+'towerFace'+'A'+'_'+'Challenged'][l]+matches[j+'towerFace'+'B'+'_'+'Challenged'][l]+matches[j+'towerFace'+'C'+'_'+'Challenged'][l])*5\n",
    "                        test2 = matches[j+'teleopScalePoints'][l]-(matches[j+'towerFace'+'A'+'_'+'Scaled'][l]+matches[j+'towerFace'+'B'+'_'+'Scaled'][l]+matches[j+'towerFace'+'C'+'_'+'Scaled'][l])*15\n",
    "                        test3 = (matches[j+'towerFace'+'A'+'_'+'Both'][l]+matches[j+'towerFace'+'B'+'_'+'Both'][l]+matches[j+'towerFace'+'C'+'_'+'Both'][l])\n",
    "                        if test3 == 1:\n",
    "                            test1 -= 5\n",
    "                            test2 -= 15\n",
    "                            if (test1 == 0.0) and (test2 == 0.0):\n",
    "                                pass\n",
    "                            else:\n",
    "                                print(event, j+'towerFace'+i+'_'+k, l, test0, test1, test2, test3)\n",
    "                                raise ValueError(\"Unknown is undetermined\")\n",
    "                        elif test3 == 0:\n",
    "                            if (test1 == 0.0) and (test2 == 0.0):\n",
    "                                pass\n",
    "                            else:\n",
    "                                print(event, j+'towerFace'+i+'_'+k, l, test0, test1, test2, test3)\n",
    "                                raise ValueError(\"Unknown is undetermined\")\n",
    "                        else:\n",
    "                            print(event, j+'towerFace'+i+'_'+k, l, test0, test1, test2, test3)\n",
    "                            raise ValueError(\"Unknown both is undetermined\")\n",
    "\n",
    "    for i in ['A', 'B', 'C']:\n",
    "        for j in ['blue_', 'red_']:\n",
    "            for k in ['Unknown']:\n",
    "                matches.drop([j+'towerFace'+i+'_'+k], axis=1, inplace=True)\n",
    "        \n",
    "    #matches.to_csv('test.csv', sep=',')\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get_matches('2016mokc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get FIRST Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_pred(event, new=False):\n",
    "    import urllib3\n",
    "    from json import loads, dump, load\n",
    "    from os.path import isfile\n",
    "    from pandas import DataFrame\n",
    "    from numpy import array as nparray\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "    http = urllib3.PoolManager()\n",
    "    auth_key = open('auth.key', 'r').read()\n",
    "    \n",
    "    if isfile('cache/first_pred/'+ event +'.json') and not new:\n",
    "        with open('cache/first_pred/'+ event +'.json', 'r') as file:\n",
    "            preds = load(file)\n",
    "    else:\n",
    "        r = http.request('GET', 'https://www.thebluealliance.com/api/v3/event/'+ event +'/predictions',\n",
    "                         headers={'X-TBA-Auth-Key': auth_key})\n",
    "        preds = loads(r.data.decode('utf-8'))['match_predictions']['qual']\n",
    "        with open('cache/first_pred/'+ event +'.json', 'w') as file:\n",
    "            dump(loads(r.data.decode('utf-8'))['match_predictions']['qual'], file)\n",
    "\n",
    "    matches = get_matches(event)\n",
    "    \n",
    "    keys = preds.keys()\n",
    "    sort_fun = lambda x: (len(x), x[-2:])\n",
    "    keys = sorted(keys, key=sort_fun)\n",
    "    n = 1\n",
    "    m = 0\n",
    "    data = []\n",
    "    for key in keys:\n",
    "        pred = preds[key]['winning_alliance']\n",
    "        actual = matches.loc[('qm', n)]['winning_alliance'].values[0]\n",
    "        if pred == actual:\n",
    "            m += 1\n",
    "        data.append((pred, actual, m/n))\n",
    "        n += 1\n",
    "        \n",
    "    data = nparray(data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_first_pred('2016abca')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Statistics Generator\n",
    "stats_gen is a function that adds a series of statistics for teams in a given event. These statistics include OPR, DPR, CCWM, OAVE, DAVE, and CPR. More information about these statistics can be found [here](https://www.chiefdelphi.com/forums/showthread.php?threadid=137451). These statistics are not cached here for more_team_stats, gradual_predictions_qm, and gradual_predictions_qm_diff all use this function in different capacities and those functions are cached. A good demonstration of this function's use is in the function more_team_stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_gen(appearances, all_stat, teams, app, rankings, if_pinv=False):\n",
    "    \"\"\"stats_gen is a function that adds a series of statistics for teams in a given\n",
    "    event. These statistics include OPR, DPR, CCWM, OAVE, DAVE, and CPR. More\n",
    "    information about these statistics can be found at the link below\n",
    "    \n",
    "    https://www.chiefdelphi.com/forums/showthread.php?threadid=137451\n",
    "    \n",
    "    These statistics are not cached here for more_team_stats, gradual_predictions_qm,\n",
    "    and gradual_predictions_qm_diff all use this function in different capacities and\n",
    "    those functions are cached. A good demonstration of this function's use is in the\n",
    "    function more_team_stats.\n",
    "    \"\"\"\n",
    "    \n",
    "    from numpy.linalg import inv, pinv, LinAlgError\n",
    "    from numpy import all as npall\n",
    "    from numpy import matmul, delete, std, mean\n",
    "    from pandas import DataFrame\n",
    "    \n",
    "    #print(appearances)\n",
    "    #print(type(appearances))\n",
    "    \n",
    "    to_delete = []\n",
    "    for i, line in enumerate(appearances):\n",
    "        if sum(line) == 0:\n",
    "            to_delete.append(i)\n",
    "\n",
    "    if len(to_delete) > 0:\n",
    "        raise ValueError(\"A team is where they shouldn't be in the appearances array\")\n",
    "        '''\n",
    "        for j, i in enumerate(to_delete):\n",
    "            i -= j\n",
    "            appearances = delete(appearances, i, axis=0)\n",
    "            appearances = delete(appearances, i, axis=1)\n",
    "        '''\n",
    "\n",
    "    try:\n",
    "        if if_pinv:\n",
    "            #print('pinv')\n",
    "            app_inv = pinv(appearances)\n",
    "        else:\n",
    "            #print('inv')\n",
    "            app_inv = inv(appearances)\n",
    "    except LinAlgError:\n",
    "        #print('pinv')\n",
    "        app_inv = pinv(appearances)\n",
    "\n",
    "    #print(app)\n",
    "    #print(all_stat.columns.values)    \n",
    "    \n",
    "    all_stat.drop(['blue_totalPoints', 'red_totalPoints', 'winning_alliance', 'blue_team1', 'blue_team2', 'blue_team3',\n",
    "                   'red_team1', 'red_team2', 'red_team3', 'blue_adjustPoints', 'red_adjustPoints', 'blue_score',\n",
    "                   'red_score'], axis=1, inplace=True)\n",
    "    team_stats = DataFrame(index=teams)\n",
    "\n",
    "    for i in ['Auto_None_a', 'Auto_Reached_a', 'Auto_Crossed_a', 'Score', 'DScore']:\n",
    "        team_stats[i] = 0\n",
    "    \n",
    "    for i in ['Auto_None_stdev', 'Auto_Reached_stdev', 'Auto_Crossed_stdev', 'Score_stdev', 'DScore_stdev']:\n",
    "        team_stats[i] = [[] for i in range(len(teams))]\n",
    "\n",
    "    for i in range(len(app)):\n",
    "        tmp = app.loc[[i+1]]\n",
    "        if tmp['blue_score'].values != -1 and tmp['red_score'].values != -1:\n",
    "            for j in ['blue_', 'red_']:\n",
    "                for k in range(1,4):\n",
    "                    if j == 'blue_':\n",
    "                        l = 'red_'\n",
    "                    else:\n",
    "                        l = 'blue_'\n",
    "                    team_stats.at[tmp[j+'team'+str(k)].values[0], 'Score'] += tmp[j+'score'].values[0]\n",
    "                    team_stats.at[tmp[j+'team'+str(k)].values[0], 'DScore'] += tmp[l+'score'].values[0]\n",
    "                    team_stats.at[tmp[j+'team'+str(k)].values[0], 'Auto_None_a'] += all_stat[j+'robot'+str(k)+'Auto_None'].loc[[i+1]]\n",
    "                    team_stats.at[tmp[j+'team'+str(k)].values[0], 'Auto_Reached_a'] += all_stat[j+'robot'+str(k)+'Auto_Reached'].loc[[i+1]]\n",
    "                    team_stats.at[tmp[j+'team'+str(k)].values[0], 'Auto_Crossed_a'] += all_stat[j+'robot'+str(k)+'Auto_Crossed'].loc[[i+1]]\n",
    "                    team_stats.at[tmp[j+'team'+str(k)].values[0], 'Score_stdev'].append(tmp[j+'score'].values[0])\n",
    "                    team_stats.at[tmp[j+'team'+str(k)].values[0], 'DScore_stdev'].append(tmp[l+'score'].values[0])\n",
    "                    team_stats.at[tmp[j+'team'+str(k)].values[0], 'Auto_None_stdev'].append(all_stat[j+'robot'+str(k)+'Auto_None'].loc[[i+1]].values)\n",
    "                    team_stats.at[tmp[j+'team'+str(k)].values[0], 'Auto_Reached_stdev'].append(all_stat[j+'robot'+str(k)+'Auto_Reached'].loc[[i+1]].values)\n",
    "                    team_stats.at[tmp[j+'team'+str(k)].values[0], 'Auto_Crossed_stdev'].append(all_stat[j+'robot'+str(k)+'Auto_Crossed'].loc[[i+1]].values)\n",
    "                    \n",
    "    for i in ['Auto_None_stdev', 'Auto_Reached_stdev', 'Auto_Crossed_stdev', 'Score_stdev', 'DScore_stdev']:\n",
    "        for team in teams:\n",
    "            team_stats.at[team, i] = std(team_stats[i][team])\n",
    "    \n",
    "    #print(team_stats)\n",
    "    for i in ['blue_', 'red_']:\n",
    "        for j in range(1,4):\n",
    "            for k in ['Auto_None', 'Auto_Reached', 'Auto_Crossed']:\n",
    "                all_stat.drop([i+'robot'+str(j)+k], axis=1, inplace=True)\n",
    "\n",
    "    rankings.sort_index(axis=0, inplace=True)\n",
    "    if npall(team_stats.index.values == rankings.index.values):\n",
    "        played = rankings['matches_played'].values\n",
    "    else:\n",
    "        raise ValueError('Stats and rankings disagree :(')\n",
    "\n",
    "    for i in ['Auto_None_a', 'Auto_Reached_a', 'Auto_Crossed_a']:\n",
    "        team_stats[i] /= played\n",
    "\n",
    "    for i in ['Ranking_Score_a','Auto_a','Scale/Challenge_a','Goals_a','Defense_a']:\n",
    "        team_stats[i] = rankings[i]\n",
    "\n",
    "    team_stats['OPR'] = matmul(app_inv, team_stats['Score'])\n",
    "    team_stats['DPR'] = matmul(app_inv, team_stats['DScore'])\n",
    "    team_stats['CCWM'] = team_stats['OPR'].values - team_stats['DPR'].values\n",
    "    team_stats['OAVE'] = team_stats['Score'] / played\n",
    "    team_stats['DAVE'] = team_stats['DScore'] / played\n",
    "    team_stats['CPR'] = team_stats['OPR'].values + team_stats['OAVE']\n",
    "\n",
    "    to_mm = DataFrame(index=teams)\n",
    "    ref_for_later = []\n",
    "    for header in all_stat.columns.values:\n",
    "        if 'blue_' in header:\n",
    "            to_mm[header[5:]+'_OPR'] = 0\n",
    "            team_stats[header[5:]+'_OAVE'] = 0\n",
    "            team_stats[header[5:]+'_CPR'] = 0\n",
    "            ref_for_later.append(header[5:])\n",
    "        else:\n",
    "            to_mm[header[4:]+'_DPR'] = 0\n",
    "            team_stats[header[4:]+'_DAVE'] = 0\n",
    "    #print(team_stats)\n",
    "\n",
    "\n",
    "    all_headers = all_stat.columns.values\n",
    "    for i in range(len(app)):\n",
    "        tmp = all_stat.loc[[i+1]].values[0]\n",
    "        tmp1 = app.loc[[i+1]]\n",
    "        if tmp1['blue_score'].values != -1 and tmp1['red_score'].values != -1:\n",
    "            for j, header in enumerate(all_headers):\n",
    "                for team in ['blue_team1', 'blue_team2', 'blue_team3', 'red_team1', 'red_team2', 'red_team3']:\n",
    "                    team_num = tmp1[team].values[0]\n",
    "                    if ('blue_' in header) and ('blue_' in team):\n",
    "                        to_mm.at[team_num, header[5:]+'_OPR'] += tmp[j]\n",
    "                        team_stats.at[team_num, header[5:]+'_OAVE'] += tmp[j]\n",
    "                    elif ('red_' in header) and ('red_' in team):\n",
    "                        to_mm.at[team_num, header[4:]+'_OPR'] += tmp[j]\n",
    "                        team_stats.at[team_num, header[4:]+'_OAVE'] += tmp[j]\n",
    "                    elif ('blue_' in header) and ('red_' in team):\n",
    "                        to_mm.at[team_num, header[5:]+'_DPR'] += tmp[j]\n",
    "                        team_stats.at[team_num, header[5:]+'_DAVE'] += tmp[j]\n",
    "                    elif ('red_' in header) and ('blue_' in team):\n",
    "                        to_mm.at[team_num, header[4:]+'_DPR'] += tmp[j]\n",
    "                        team_stats.at[team_num, header[4:]+'_DAVE'] += tmp[j]\n",
    "                    else:\n",
    "                        raise ValueError('Something is wrong')\n",
    "\n",
    "    ts_headers = team_stats.columns.values\n",
    "    for header in ts_headers:\n",
    "        if header[-5:] == '_OAVE' or header[-5:] == '_DAVE':\n",
    "            team_stats[header] /= played\n",
    "\n",
    "    mm_headers = to_mm.columns.values\n",
    "    for header in mm_headers:\n",
    "        team_stats[header] = matmul(app_inv, to_mm[header].values)\n",
    "\n",
    "    for header in ref_for_later:\n",
    "        team_stats[header+'_CPR'] = team_stats[header+'_OPR'].values + team_stats[header+'_OAVE']\n",
    "\n",
    "    team_stats.drop(['Score', 'DScore'], axis=1, inplace=True)\n",
    "        \n",
    "    headers = team_stats.columns.values\n",
    "    for header in headers:\n",
    "        average = mean(team_stats[header].values)\n",
    "        tmp = []\n",
    "        for stat in team_stats[header].values:\n",
    "            tmp.append(stat-average)\n",
    "        team_stats[header+'_from_mean'] = tmp\n",
    "        \n",
    "    #print(team_stats.columns.values)\n",
    "    \n",
    "    return team_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Team Statistics\n",
    "more_team_stats is a function that provides additional statistics to those provided by The Blue Alliance. See the function stats_gen for more details about these statistics. These statistics are cached after they are created, in the directory 'cache/more_team_stats/'. The statistics can updated with new=True. The output shape from this function is (number of teams, 369)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def more_team_stats(event, new=False):\n",
    "    \"\"\"more_team_stats is a function that provides additional statistics to those\n",
    "    provided by The Blue Alliance. See the function stats_gen for more details about\n",
    "    these statistics. These statistics are cached after they are created, in the\n",
    "    directory 'cache/more_team_stats/'. The statistics can updated with new=True. The\n",
    "    output shape from this function is (number of teams, 369).\n",
    "    \n",
    "    Examples:\n",
    "        more_team_stats('2016mokc') returns the statistics for 2016mokc and caches the\n",
    "            data if it hasn't been already\n",
    "        more_team_stats('2016abca', True) forces more_team_stats to recaculate the\n",
    "            statistics and returns the statistics for 2016abca\n",
    "    \"\"\"\n",
    "    \n",
    "    from numpy import unique, zeros\n",
    "    from pandas import DataFrame, read_csv\n",
    "    from os.path import isfile\n",
    "    \n",
    "    if isfile('cache/more_team_stats/'+ event +'.csv') and not new:\n",
    "        team_stats = read_csv('cache/more_team_stats/'+ event +'.csv')\n",
    "        team_stats.set_index(team_stats.columns.values[0], inplace=True)\n",
    "        del team_stats.index.name\n",
    "        return team_stats\n",
    "    else:\n",
    "        matches = get_matches(event, new)\n",
    "        rankings = get_rankings(event, new)\n",
    "        all_stat = matches.loc[['qm']].reset_index(level=0, drop=True)\n",
    "        app = all_stat[['blue_team1', 'blue_team2', 'blue_team3', 'blue_score',\n",
    "                        'red_team1', 'red_team2', 'red_team3', 'red_score']]\n",
    "\n",
    "        teams = unique(app[['blue_team1', 'blue_team2', 'blue_team3', 'red_team1', 'red_team2', 'red_team3']])\n",
    "        teams.sort()\n",
    "        #print(teams)\n",
    "\n",
    "        length = len(teams)\n",
    "        appearances = zeros([length, length])\n",
    "\n",
    "        appearances = DataFrame(appearances, teams, teams)\n",
    "        #appearances.at['frc1108', 'frc1723'] += 1 #row, column\n",
    "        #print(app)\n",
    "\n",
    "        for i in range(len(app)):\n",
    "            tmp = app.loc[[i+1]].values.reshape(-1,)\n",
    "            if len(tmp) == 8:\n",
    "                if tmp[3] != -1 and tmp[7] != -1:\n",
    "                    blue_tmp = tmp[:3]\n",
    "                    for team in blue_tmp:\n",
    "                        appearances.at[team, blue_tmp[0]] += 1\n",
    "                        appearances.at[team, blue_tmp[1]] += 1\n",
    "                        appearances.at[team, blue_tmp[2]] += 1\n",
    "\n",
    "                    red_tmp = tmp[4:7]\n",
    "                    for team in red_tmp:\n",
    "                        appearances.at[team, red_tmp[0]] += 1\n",
    "                        appearances.at[team, red_tmp[1]] += 1\n",
    "                        appearances.at[team, red_tmp[2]] += 1\n",
    "        appearances = appearances.values\n",
    "\n",
    "        #####################################################################################################################\n",
    "        #appearances, all_stat(raw match data), teams, app(reduced match data), rankings = get_rankings(...)\n",
    "        team_stats = stats_gen(appearances, all_stat, teams, app, rankings)\n",
    "\n",
    "        team_stats.to_csv('cache/more_team_stats/'+ event +'.csv')\n",
    "            \n",
    "        return team_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#more_team_stats('2016mokc', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_matches(event, new=False):\n",
    "    from numpy import array as nparray\n",
    "    from numpy import save, load\n",
    "    from pandas import DataFrame, read_csv\n",
    "    from os.path import isfile\n",
    "    \n",
    "    if isfile('cache/predict_matches/'+ event +'.csv') and isfile('cache/predict_matches/'+ event +'.npy') and not new:\n",
    "        predict_stats = read_csv('cache/predict_matches/'+ event +'.csv')\n",
    "        predict_stats.set_index(predict_stats.columns.values[0], inplace=True)\n",
    "        del predict_stats.index.name\n",
    "        blue_win = load('cache/predict_matches/'+ event +'.npy')\n",
    "        return predict_stats, blue_win\n",
    "    \n",
    "    matches = get_matches(event, new)\n",
    "    stats = more_team_stats(event)#, new)\n",
    "\n",
    "    fs = matches.loc[['qm']].reset_index(level=0, drop=True).sort_index()\n",
    "\n",
    "    blue_win = []\n",
    "    predict_stats = DataFrame(columns=stats.columns.values.tolist())\n",
    "\n",
    "    for i in range(len(fs)):\n",
    "        predict_stats = predict_stats.append(stats.loc[[fs.iloc[[i]]['blue_team1'].values[0]]], ignore_index=True)\n",
    "        predict_stats.iloc[[i]] += stats.loc[[fs.iloc[[i]]['blue_team2'].values[0]]].values\n",
    "        predict_stats.iloc[[i]] += stats.loc[[fs.iloc[[i]]['blue_team3'].values[0]]].values\n",
    "        predict_stats.iloc[[i]] -= stats.loc[[fs.iloc[[i]]['red_team1'].values[0]]].values\n",
    "        predict_stats.iloc[[i]] -= stats.loc[[fs.iloc[[i]]['red_team2'].values[0]]].values\n",
    "        predict_stats.iloc[[i]] -= stats.loc[[fs.iloc[[i]]['red_team3'].values[0]]].values\n",
    "        if fs.iloc[[i]]['blue_score'].values[0] >= fs.iloc[[i]]['red_score'].values[0]: #I'll give ties to blue for now\n",
    "            blue_win.append(1)\n",
    "        else:\n",
    "            blue_win.append(0)\n",
    "\n",
    "    blue_win = nparray(blue_win)\n",
    "    \n",
    "    #print(blue_win)\n",
    "    \n",
    "    predict_stats.to_csv('cache/predict_matches/'+ event +'.csv')\n",
    "    save('cache/predict_matches/'+ event +'.npy', blue_win)\n",
    "    \n",
    "    return predict_stats, blue_win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#predict_matches('2016mokc', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
