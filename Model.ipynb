{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def updater():\n",
    "    import ipynb.fs.defs.Web_Get as wg\n",
    "    from tqdm import tqdm\n",
    "    print(dir(wg))\n",
    "    events = wg.get_all_events(6, False)\n",
    "    \n",
    "    with tqdm(total=len(events)) as pbar:\n",
    "        for event in events:\n",
    "            #print(event)\n",
    "            new=True\n",
    "            #new=False\n",
    "            #wg.get_rankings(event, new=new)\n",
    "            #wg.get_matches(event, new=new)\n",
    "            wg.get_first_pred(event, new=new)\n",
    "            #wg.more_team_stats(event, new=new)\n",
    "            wg.predict_matches(event, new=new)\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#updater()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_data(with_rs=True, week=6, only=False):\n",
    "    import ipynb.fs.defs.Web_Get as wg\n",
    "    from tqdm import tqdm\n",
    "    import numpy as np\n",
    "\n",
    "    events = wg.get_all_events(week, only)\n",
    "    \n",
    "    n = 0\n",
    "    print(\"Loading data\")\n",
    "    with tqdm(total=len(events)) as pbar:\n",
    "        for event in events:\n",
    "            stats, blue_wins = wg.predict_matches(event)\n",
    "            y_tmp = blue_wins\n",
    "            x_tmp = stats\n",
    "            if n == 0:\n",
    "                X = x_tmp\n",
    "                y = y_tmp\n",
    "                n += 1\n",
    "            else:\n",
    "                X = X.append(x_tmp, ignore_index=True)\n",
    "                y = np.append(y, y_tmp)\n",
    "            pbar.update(1)\n",
    "    if not with_rs:\n",
    "        X.drop(['Ranking_Score_a', 'tba_rpEarned_OAVE', 'tba_rpEarned_CPR', 'tba_rpEarned_OPR', 'tba_rpEarned_DAVE', 'tba_rpEarned_DPR',\n",
    "               'Ranking_Score_a_from_mean', 'tba_rpEarned_OAVE_from_mean', 'tba_rpEarned_CPR_from_mean', 'tba_rpEarned_OPR_from_mean', 'tba_rpEarned_DAVE_from_mean', 'tba_rpEarned_DPR_from_mean'], axis=1, inplace=True)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_match_data(week=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc_model(C, g, X_train, y_train, beta, random_state, return_grid_fit=False):\n",
    "    from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\n",
    "    from sklearn.metrics import fbeta_score, accuracy_score, make_scorer, average_precision_score\n",
    "    from sklearn.svm import SVC\n",
    "\n",
    "    clf = SVC(random_state=random_state, cache_size=1000)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    parameters = {'C':C, 'tol':[1e-4], 'gamma':g}\n",
    "\n",
    "    cv = StratifiedShuffleSplit(n_splits = 4, test_size = 0.20)\n",
    "\n",
    "    scorer1 = make_scorer(fbeta_score, beta=beta)\n",
    "    scorer2 = make_scorer(accuracy_score)\n",
    "    scorer3 = make_scorer(average_precision_score)\n",
    "    scoring = {'scorer1': scorer1, 'scorer2': scorer2,'scorer3': scorer3}\n",
    "\n",
    "    grid_obj = GridSearchCV(clf, parameters, scoring=scoring, refit='scorer1', n_jobs=8, cv=cv)\n",
    "\n",
    "    grid_fit = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "    best_clf = grid_fit.best_estimator_\n",
    "    \n",
    "    if return_grid_fit:\n",
    "        return clf, best_clf, grid_fit\n",
    "    else:\n",
    "        return clf, best_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matches(week=6, with_rs=True, only=False, C=[10.984375], g=[0.0028]):\n",
    "    from sklearn.metrics import fbeta_score, accuracy_score, average_precision_score\n",
    "    import ipynb.fs.defs.Web_Get as wg\n",
    "    from tqdm import tqdm\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    beta = 0.5\n",
    "    random_state = 42\n",
    "    \n",
    "    events = wg.get_all_events(week, only)\n",
    "    \n",
    "    n = 0\n",
    "    print(\"Loading match data to train on\")\n",
    "    with tqdm(total=len(events)) as pbar:\n",
    "        for event in events:\n",
    "            stats, blue_wins = wg.predict_matches(event)\n",
    "            y_tmp = blue_wins\n",
    "            x_tmp = stats\n",
    "            if n == 0:\n",
    "                X = x_tmp\n",
    "                y = y_tmp\n",
    "                n += 1\n",
    "            else:\n",
    "                X = X.append(x_tmp, ignore_index=True)\n",
    "                y = np.append(y, y_tmp)\n",
    "            pbar.update(1)\n",
    "    if not with_rs:\n",
    "        X.drop(['Ranking_Score_a', 'tba_rpEarned_OAVE', 'tba_rpEarned_CPR', 'tba_rpEarned_OPR', 'tba_rpEarned_DAVE', 'tba_rpEarned_DPR',\n",
    "               'Ranking_Score_a_from_mean', 'tba_rpEarned_OAVE_from_mean', 'tba_rpEarned_CPR_from_mean', 'tba_rpEarned_OPR_from_mean', 'tba_rpEarned_DAVE_from_mean', 'tba_rpEarned_DPR_from_mean'], axis=1, inplace=True)\n",
    "    #print(X.shape)\n",
    "    #print(y.shape)\n",
    "    \n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    headers = X.columns.values\n",
    "    fit_scaler = MinMaxScaler([-1,1]).fit(X[headers])\n",
    "    X[headers] = fit_scaler.transform(X[headers])\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                        y, \n",
    "                                                        test_size = 0.15,\n",
    "                                                        random_state=random_state)\n",
    "\n",
    "    print(\"Training set has {} samples and {} features.\".format(X_train.shape[0], X_train.shape[1]))\n",
    "    print(\"Testing set has {} samples and {} features.\".format(X_test.shape[0], X_train.shape[1]))\n",
    "\n",
    "    clf, best_clf = svc_model(C, g, X_train, y_train, beta, random_state)\n",
    "        \n",
    "    #print(best_clf)\n",
    "\n",
    "    predictions = clf.predict(X_test)\n",
    "    predictions_x = clf.predict(X_train)\n",
    "    #print(clf.get_params)\n",
    "    best_predictions = best_clf.predict(X_test)\n",
    "    best_predictions_x = best_clf.predict(X_train)\n",
    "\n",
    "    print()\n",
    "    print(\"Unoptimized model\\n------\")\n",
    "    print(\"Accuracy score on training data: {:.4f}\".format(accuracy_score(y_train, predictions_x)))\n",
    "    print(\"Accuracy score on testing data: {:.4f}\".format(accuracy_score(y_test, predictions)))\n",
    "    print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, predictions, beta = beta)))\n",
    "    print(\"Average precision score on testing data: {:.4f}\".format(average_precision_score(y_test, predictions)))\n",
    "    print(\"\\nOptimized Model\\n------\")\n",
    "    print(\"Final accuracy score on training data: {:.4f}\".format(accuracy_score(y_train, best_predictions_x)))\n",
    "    print(\"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\n",
    "    print(\"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta = beta)))\n",
    "    print(\"Final average precision score on testing data: {:.4f}\".format(average_precision_score(y_test, best_predictions)))\n",
    "    print()\n",
    "\n",
    "    #pd.DataFrame(grid_fit.cv_results_).to_csv('future2.csv', sep=',')\n",
    "\n",
    "    test = pd.DataFrame(np.matmul(best_clf.dual_coef_, best_clf.support_vectors_)+best_clf.intercept_, columns=X.columns.values)\n",
    "    test_t = test.transpose()\n",
    "    print(test_t)\n",
    "    print(test_t.nlargest(15, 0))\n",
    "    print()\n",
    "    print(test_t.nsmallest(15, 0))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matches('dist_cmps', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_matches(week=6, with_rs=True, only=False, C=[10.984375], g=[0.0028], num=1):\n",
    "    from sklearn.metrics import fbeta_score, accuracy_score, average_precision_score\n",
    "    import ipynb.fs.defs.Web_Get as wg\n",
    "    from tqdm import tqdm\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    beta = 0.5\n",
    "    random_state = 42\n",
    "    \n",
    "    events = wg.get_all_events(week, only)\n",
    "    \n",
    "    n = 0\n",
    "    print(\"Loading match data to train on\")\n",
    "    with tqdm(total=len(events)) as pbar:\n",
    "        for event in events:\n",
    "            stats, blue_wins = wg.predict_matches(event)\n",
    "            y_tmp = blue_wins\n",
    "            x_tmp = stats\n",
    "            if n == 0:\n",
    "                X = x_tmp\n",
    "                y = y_tmp\n",
    "                n += 1\n",
    "            else:\n",
    "                X = X.append(x_tmp, ignore_index=True)\n",
    "                y = np.append(y, y_tmp)\n",
    "            pbar.update(1)\n",
    "    if not with_rs:\n",
    "        X.drop(['Ranking_Score_a', 'tba_rpEarned_OAVE', 'tba_rpEarned_CPR', 'tba_rpEarned_OPR', 'tba_rpEarned_DAVE', 'tba_rpEarned_DPR',\n",
    "               'Ranking_Score_a_from_mean', 'tba_rpEarned_OAVE_from_mean', 'tba_rpEarned_CPR_from_mean', 'tba_rpEarned_OPR_from_mean', 'tba_rpEarned_DAVE_from_mean', 'tba_rpEarned_DPR_from_mean'], axis=1, inplace=True)\n",
    "    #print(X.shape)\n",
    "    #print(y.shape)\n",
    "        \n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components=num, svd_solver='randomized')\n",
    "    pca.fit(X)\n",
    "    X = pca.transform(X)\n",
    "    \n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    X = MinMaxScaler([-1,1]).fit_transform(X)\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                        y, \n",
    "                                                        test_size = 0.15,\n",
    "                                                        random_state=random_state)\n",
    "\n",
    "    print(\"Training set has {} samples and {} features.\".format(X_train.shape[0], X_train.shape[1]))\n",
    "    print(\"Testing set has {} samples and {} features.\".format(X_test.shape[0], X_train.shape[1]))\n",
    "\n",
    "    clf, best_clf = svc_model(C, g, X_train, y_train, beta, random_state)\n",
    "    \n",
    "    #print(best_clf)\n",
    "\n",
    "    predictions = clf.predict(X_test)\n",
    "    predictions_x = clf.predict(X_train)\n",
    "    #print(clf.get_params)\n",
    "    best_predictions = best_clf.predict(X_test)\n",
    "    best_predictions_x = best_clf.predict(X_train)\n",
    "\n",
    "    print()\n",
    "    print(\"Unoptimized model\\n------\")\n",
    "    print(\"Accuracy score on training data: {:.4f}\".format(accuracy_score(y_train, predictions_x)))\n",
    "    print(\"Accuracy score on testing data: {:.4f}\".format(accuracy_score(y_test, predictions)))\n",
    "    print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, predictions, beta = beta)))\n",
    "    print(\"Average precision score on testing data: {:.4f}\".format(average_precision_score(y_test, predictions)))\n",
    "    print(\"\\nOptimized Model\\n------\")\n",
    "    print(\"Final accuracy score on training data: {:.4f}\".format(accuracy_score(y_train, best_predictions_x)))\n",
    "    print(\"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\n",
    "    print(\"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta = beta)))\n",
    "    print(\"Final average precision score on testing data: {:.4f}\".format(average_precision_score(y_test, best_predictions)))\n",
    "    print()\n",
    "    #print(np.matmul(best_clf.dual_coef_, best_clf.support_vectors_)+best_clf.intercept_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca_matches('qm', True, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def future_matches_pred(week, with_rs=True, only=False, C=[10.984375], g=[0.0028]):\n",
    "    from sklearn.metrics import fbeta_score, accuracy_score, average_precision_score\n",
    "    import ipynb.fs.defs.Web_Get as wg\n",
    "    from tqdm import tqdm\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    beta = 0.5\n",
    "    random_state = 42\n",
    "    \n",
    "    if week <= 6:\n",
    "        events = wg.get_all_events(week=week-1, only=only)\n",
    "    elif week == 7:\n",
    "        events = wg.get_all_events(week=6, only=only)\n",
    "    elif week ==8:\n",
    "        events = wg.get_all_events(week=6, only=only)\n",
    "    \n",
    "    n = 0\n",
    "    print(\"Loading match data to train on\")\n",
    "    with tqdm(total=len(events)) as pbar:\n",
    "        for event in events:\n",
    "            stats, blue_wins = wg.predict_matches(event)\n",
    "            y_tmp = blue_wins\n",
    "            x_tmp = stats\n",
    "            if n == 0:\n",
    "                X = x_tmp\n",
    "                y = y_tmp\n",
    "                n += 1\n",
    "            else:\n",
    "                X = X.append(x_tmp, ignore_index=True)\n",
    "                y = np.append(y, y_tmp)\n",
    "            pbar.update(1)\n",
    "    if not with_rs:\n",
    "        X.drop(['Ranking_Score_a', 'tba_rpEarned_OAVE', 'tba_rpEarned_CPR', 'tba_rpEarned_OPR', 'tba_rpEarned_DAVE', 'tba_rpEarned_DPR',\n",
    "               'Ranking_Score_a_from_mean', 'tba_rpEarned_OAVE_from_mean', 'tba_rpEarned_CPR_from_mean', 'tba_rpEarned_OPR_from_mean', 'tba_rpEarned_DAVE_from_mean', 'tba_rpEarned_DPR_from_mean'], axis=1, inplace=True)\n",
    "    #print(X.shape)\n",
    "    #print(y.shape)\n",
    "    \n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    headers = X.columns.values\n",
    "    fit_scaler = MinMaxScaler([-1,1]).fit(X[headers])\n",
    "    X[headers] = fit_scaler.transform(X[headers])\n",
    "    \n",
    "    print(\"Training set has {} samples and {} features.\".format(X.shape[0], X.shape[1]))\n",
    "    \n",
    "    clf, best_clf = svc_model(C, g, X, y, beta, random_state)\n",
    "    \n",
    "    if week <= 6:\n",
    "        events = wg.get_all_events(week=week, only=True)\n",
    "    elif week == 7:\n",
    "        events = wg.get_dist_cmps()\n",
    "    elif week ==8:\n",
    "        events = wg.get_cmps()\n",
    "    \n",
    "    n = 0\n",
    "    print()\n",
    "    print(\"Loading future data to predict on\")\n",
    "    with tqdm(total=len(events)) as pbar:\n",
    "        for event in events:\n",
    "            stats, blue_wins = wg.predict_matches(event)\n",
    "            preds = wg.get_first_pred(event)\n",
    "            \n",
    "            y_tmp = blue_wins\n",
    "            x_tmp = stats\n",
    "            \n",
    "            pred = np.array([1 if x=='blue' else 0 for x in preds[:,0]])\n",
    "            actual = np.array([1 if x=='blue' else 0 for x in preds[:,1]])\n",
    "            \n",
    "            if n == 0:\n",
    "                X1 = x_tmp\n",
    "                y1 = y_tmp\n",
    "                pred1 = pred\n",
    "                actual1 = actual\n",
    "                n += 1\n",
    "            else:\n",
    "                X1 = X1.append(x_tmp, ignore_index=True)\n",
    "                y1 = np.append(y1, y_tmp)\n",
    "                pred1 = np.append(pred1, pred)\n",
    "                actual1 = np.append(actual1, actual)\n",
    "            pbar.update(1)\n",
    "\n",
    "    headers = X1.columns.values\n",
    "    X1[headers] = fit_scaler.transform(X1[headers])\n",
    "    if not with_rs:\n",
    "        X.drop(['Ranking_Score_a', 'tba_rpEarned_OAVE', 'tba_rpEarned_CPR', 'tba_rpEarned_OPR', 'tba_rpEarned_DAVE', 'tba_rpEarned_DPR',\n",
    "                'Ranking_Score_a_from_mean', 'tba_rpEarned_OAVE_from_mean', 'tba_rpEarned_CPR_from_mean', 'tba_rpEarned_OPR_from_mean', 'tba_rpEarned_DAVE_from_mean', 'tba_rpEarned_DPR_from_mean'], axis=1, inplace=True)\n",
    "\n",
    "    predictions = best_clf.predict(X1)\n",
    "\n",
    "    print(accuracy_score(y1, predictions))\n",
    "    print(fbeta_score(y1, predictions, beta = beta))\n",
    "    print(average_precision_score(y1, predictions))\n",
    "    print()\n",
    "    print(accuracy_score(actual1, pred1))\n",
    "    print(fbeta_score(actual1, pred1, beta = beta))\n",
    "    print(average_precision_score(actual1, pred1))\n",
    "    \n",
    "    mine_real = np.equal(predictions, y1)\n",
    "    first_real = np.equal(pred1, y1)\n",
    "    \n",
    "    both_wrong = 0\n",
    "    both_right = 0\n",
    "    mine_right = 0\n",
    "    first_right = 0\n",
    "    for i, j in zip(mine_real, first_real):\n",
    "        if i == False and j == False:\n",
    "            both_wrong += 1\n",
    "        elif i == True and j == True:\n",
    "            both_right += 1\n",
    "        elif i == True and j == False:\n",
    "            mine_right += 1\n",
    "        elif i == False and j == True:\n",
    "            first_right += 1\n",
    "            \n",
    "    return both_right, both_wrong, mine_right, first_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#future_matches_pred(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
